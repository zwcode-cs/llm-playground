This folder contains a multi-GPU LLaMa training example for HPC Slurm environment.

## Install dependencies
`bash install_dep.sh`

## Training
Single-node multi-GPU: ``sbatch run_train_singlenode.q`
Multi-node multi-GPU (WIP): `sbatch run_train_multinode.q`

## Inference
